{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVmi8/RaVqEcv+5TM4GYsQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1.순환 신경망(Recurrent Neural Network)**\n","* 시계열 또는 자연어와 같은 Sequence 데이터를 모델링하는 데 강력한 신경망. 시계열 데이터나 시퀀스 데이터를 잘 처리\n","* 예) 주식 가격, 텍스트 데이터, 오디오 데이터\n","* Sequence: 단어의 문장. 연결되어 있는 정보\n","<center><img src='https://velog.velcdn.com/images/softwarerbfl/post/d6c16b45-ef7d-4f3c-9a4a-efa54d2de587/image.png' with=400></center>"],"metadata":{"id":"nfd26TElZbQd"}},{"cell_type":"markdown","source":["### 1-1. RNN동작 방식\n","* 은닉층에 노드에서 활성화 함수를 통해 나온 결과값을 다시 출력층 방향으로 보내면서 은닉층 노드의 다음 계산의 입력으로 보내는 것이 특징\n","* 셀(cell): 은닉층에서 활성화 함수를 통해 나온 결과를 내보내는 역할을 하는 것. 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수행\n","* 은닉 상태(hidden state): 셀이 출력층 방향 또는 다음 시점인 t+1의 자신에게 보내는 값\n","\n","```\n","rnn = torch.nn.RNN(input_size, hidden_size)\n","outputs, state = rnn(input_data)\n","# state: hidden state\n","```"],"metadata":{"id":"5fsF0qMwsuxj"}},{"cell_type":"markdown","source":["### 1-2. inupt size\n","* 단어가 입력되면 각 글자를 백터의 형태로 변환하여 ont-hot encoding 해주는 과정이 필요\n","* \"hello\"\n","    * h = [1, 0, 0, 0]\n","    * e = [0, 1, 0 , 0]\n","    * l = [0, 0, 1, 0]\n","    * o = [0, 0, 0, 1]\n","* input size를 4\n","* input data의 세번째 차원으로 입력"],"metadata":{"id":"x5LdMkqNZfk7"}},{"cell_type":"markdown","source":["### 1-3. hidden state size\n","* hidden state의 size는 output의 세번째 차원\n","* output size와 같음\n","* 셀에서 연산된 결과를 두가지로 나눠 하나는 output으로 출력되고, 다른 하나는 hidden state로 다음 step에 그대로 저장하고 전해짐"],"metadata":{"id":"lntS7MW8vdqj"}},{"cell_type":"markdown","source":["### 1-4. Sequence Length\n","* Sequence가 총 몇 개인지를 나타냄\n","    * \"hello\"\n","        * x0 = [1, 0, 0, 0]\n","        * x1 = [0, 1, 0 , 0]\n","        * x2 = [0, 0, 1, 0]\n","        * x3 = [0, 0, 1, 0]\n","        * x4 = [0, 0, 0, 1]\n","        * => 'hello'를 입력으로 보내면 sequence length는 5\n","* \"hello\"를 입력으로 보내면 sequence length는 5\n","* PyTorch에서는 모델이 sequence length를 알아서 파악하기 때문에 파라미터로 전달해 줄 필요가 없음"],"metadata":{"id":"lFXxsP8svdss"}},{"cell_type":"markdown","source":["### 1-5. Batch Size\n","* 여러 데이터를 묶어 하나의 batch로 만들어 학습을 진행\n","* h, e, l, o를 가지고 만들 수 있는 데이터([h, e, l, l, 0][e, o, l, l, l][l, l, e, e, l]처럼) 중 배치사이즈로 묶어 학습을 진행\n","* batch size를 모델에서 파악하고 output data, input data에서의 첫번째 차원에 위치함"],"metadata":{"id":"G49I3KMZvduy"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.nn import RNN"],"metadata":{"id":"Vu1nB_Ogxinz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_size = 4  # 입력 데이터의 크기. 각 입력 벡터의 길이\n","hidden_size = 2  # 은닉 상태의 크기. RNN 셀 내부의 은닉 상태 벡터의 크기"],"metadata":{"id":"g7ydu4L4xmab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 입력 데이터를 one-hot encoding\n","h = [1, 0, 0, 0]\n","e = [0, 1, 0, 0]\n","l = [0, 0, 1, 0]\n","o = [0, 0, 0, 1]"],"metadata":{"id":"iER_FsDdxqVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_data_np = np.array([[h, e, l, l, o],\n","                          [e, o, l, l, l],\n","                          [l, l, e, e, l]], dtype = np.float32)\n","# numpy 배열을 PyTorch Tensor로 변환\n","input_data = torch.Tensor(input_data_np)"],"metadata":{"id":"jUOrN7Tbx6Wz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RNN 모델을 정의 (입력 크기와 은닉 상태 크기를 인자로)\n","rnn = RNN(input_size, hidden_size)  # 4, 2\n","# 입력 데이터를 RNN에 넣어 출력을 계산 => outputs와 status를 반환\n","outputs, state = rnn(input_data)"],"metadata":{"id":"crUu-oInZjgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 출력 데이터\n","outputs"],"metadata":{"id":"g0rFEaj-Zjps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719467939169,"user_tz":-540,"elapsed":12,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"9d6c4231-41d1-492e-8b64-1aaf98d2220d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.0453, -0.4226],\n","         [ 0.6697, -0.7710],\n","         [-0.0649, -0.4790],\n","         [-0.0649, -0.4790],\n","         [ 0.7129, -0.4935]],\n","\n","        [[ 0.7190, -0.6954],\n","         [ 0.4997,  0.0411],\n","         [ 0.0523, -0.3278],\n","         [ 0.0523, -0.3278],\n","         [-0.4470, -0.0427]],\n","\n","        [[-0.4256,  0.0462],\n","         [-0.3929, -0.3382],\n","         [ 0.6772, -0.6975],\n","         [ 0.6772, -0.6975],\n","         [ 0.2442, -0.5855]]], grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# 은닉 상태\n","state  # 5개의 결과 => input데이터가 5개라서 => [h, e, l, l, o] 5개"],"metadata":{"id":"vjqkoXMlZjrz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719467939169,"user_tz":-540,"elapsed":12,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"1b3ab6d6-8c2a-498f-f228-6dfcaccdc4d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.4256,  0.0462],\n","         [-0.3929, -0.3382],\n","         [ 0.6772, -0.6975],\n","         [ 0.6772, -0.6975],\n","         [ 0.2442, -0.5855]]], grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# test를 사용하여 고유한 문자 집합을 만들기\n","test = 'hello! world'\n","string_set = list(set(test))\n","print(string_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKiUAbphyhpi","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":11,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"2d6445a2-facb-4b04-bbaf-b3302a5097ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['o', 'r', 'e', ' ', 'd', 'h', 'w', '!', 'l']\n"]}]},{"cell_type":"code","source":["# 각 문자를 인덱스로 매핑하는 사전을 생성하기\n","string_dic = {c: i for i, c in enumerate(string_set)}\n","print(string_dic)  # 인덱스화 됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nPZ6pwCyqth","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":10,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"a9fc3648-70cc-4bf9-cff7-906d1b82ee8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'o': 0, 'r': 1, 'e': 2, ' ': 3, 'd': 4, 'h': 5, 'w': 6, '!': 7, 'l': 8}\n"]}]},{"cell_type":"code","source":["# 이를 기반으로 입력 벡터와 은닉 상태 벡터의 크기를 설정\n","input_size = len(string_dic)\n","print(input_size)\n","hidden_size = len(string_dic)\n","print(hidden_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MmH5RNHy19E","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":9,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"938e80f0-28cd-4984-9fbd-4d6ae66dbe3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","9\n"]}]},{"cell_type":"code","source":["# test라는 문자열을 string_dic이라는 사전에 기반하여 인덱스 리스트로 변환\n","test_idx = [string_dic[c] for c in test]\n","print(test_idx)  # 인덱스가 나옴"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCwjC0vvy1_j","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":8,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"532f84ea-2b5b-4356-d658-4b934d660e1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 2, 8, 8, 0, 7, 3, 6, 0, 1, 8, 4]\n"]}]},{"cell_type":"code","source":["# test_idx 리스트를 x_data로 변환\n","x_data = [test_idx[:]]\n","print(x_data)  # 하나 더 감싸서 나옴"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0F31e1pVyqwJ","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":7,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"2f1c208c-b9d5-42ee-c98b-c78934642131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[5, 2, 8, 8, 0, 7, 3, 6, 0, 1, 8, 4]]\n"]}]},{"cell_type":"markdown","source":["```\n","[array([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]\n","```"],"metadata":{"id":"KgasBdbGIZkL"}},{"cell_type":"code","source":["# x_data 리스트의 각 요소를 one-hot 인코딩 형식으로 변환하여 'x_one_hot '리스트를 만들기\n","x_one_hot = [np.eye(input_size)[x] for x in x_data]\n","print(x_one_hot)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gCtZgutIIMT","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":6,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"7877460a-0e75-4d46-eb14-dbec92c8f2ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.]])]\n"]}]},{"cell_type":"code","source":["y_data = [test_idx[:]]\n","print(y_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qs-2MAsLL7fZ","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":5,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"2c9d0acc-04e1-45b7-e6a6-30d5f3253507"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[5, 2, 8, 8, 0, 7, 3, 6, 0, 1, 8, 4]]\n"]}]},{"cell_type":"code","source":["X = torch.FloatTensor(x_one_hot)\n","y = torch.LongTensor(y_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uldoCwJ6L7hp","executionInfo":{"status":"ok","timestamp":1719467939170,"user_tz":-540,"elapsed":4,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"2fa93c90-4579-47c0-8636-2e9168bab1ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-25a499c695e1>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n","  X = torch.FloatTensor(x_one_hot)\n"]}]},{"cell_type":"code","source":["rnn = RNN(input_size, hidden_size)\n","loss_fun = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(rnn.parameters(), lr = 0.1)"],"metadata":{"id":"xNlURIVjMZGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RNN 모델 학습"],"metadata":{"id":"VZqqWXrPZpXO"}},{"cell_type":"code","source":["# outputs, state = rnn(X)\n","# loss: x, predition: x(idx), predition_str: s(str)\n","# hello! world\n","epochs = 100\n","\n","for i in range(epochs):\n","    optimizer.zero_grad()\n","    outputs, state = rnn(X)\n","\n","    # (배치사이즈, 시퀀스길이, 히든사이즈)\n","    # outputs: (1, 12, 12) -> (12, 12)\n","    # y: (1, 12) -> (12,)\n","    loss = loss_fun(outputs.view(-1, input_size), y.view(-1))\n","    loss.backward()\n","    optimizer.step()\n","\n","    result = outputs.data.numpy().argmax(axis = 2)\n","    result_str = ''.join(string_set[ch] for ch in np.squeeze(result))\n","    print(i, 'loss: ', loss)\n","    print('prediction: ', result, ' prediction_str: ', result_str)\n","    # 8부터 제대로 예측"],"metadata":{"id":"Jzew8DL-ZoUc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719467943334,"user_tz":-540,"elapsed":617,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"3be2edf9-04c5-4144-9691-a9f09d35eff3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 loss:  tensor(2.1904, grad_fn=<NllLossBackward0>)\n","prediction:  [[2 2 7 7 0 6 0 8 0 0 7 2]]  prediction_str:  ee!!owoloo!e\n","1 loss:  tensor(1.9756, grad_fn=<NllLossBackward0>)\n","prediction:  [[0 2 8 8 0 8 0 8 0 0 8 2]]  prediction_str:  oellololoole\n","2 loss:  tensor(1.8089, grad_fn=<NllLossBackward0>)\n","prediction:  [[0 2 8 8 0 8 0 8 0 0 8 0]]  prediction_str:  oellololoolo\n","3 loss:  tensor(1.6759, grad_fn=<NllLossBackward0>)\n","prediction:  [[8 2 8 8 0 8 0 8 0 8 8 8]]  prediction_str:  lellolololll\n","4 loss:  tensor(1.5601, grad_fn=<NllLossBackward0>)\n","prediction:  [[8 2 8 8 0 8 3 8 0 8 8 8]]  prediction_str:  lellol lolll\n","5 loss:  tensor(1.4528, grad_fn=<NllLossBackward0>)\n","prediction:  [[8 2 8 8 0 8 3 8 0 1 8 4]]  prediction_str:  lellol lorld\n","6 loss:  tensor(1.3508, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 8 0 1 8 4]]  prediction_str:  hello! lorld\n","7 loss:  tensor(1.2543, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 8 0 1 8 4]]  prediction_str:  hello! lorld\n","8 loss:  tensor(1.1684, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","9 loss:  tensor(1.0970, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","10 loss:  tensor(1.0389, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","11 loss:  tensor(0.9922, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","12 loss:  tensor(0.9547, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","13 loss:  tensor(0.9246, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","14 loss:  tensor(0.9000, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","15 loss:  tensor(0.8793, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","16 loss:  tensor(0.8617, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","17 loss:  tensor(0.8466, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","18 loss:  tensor(0.8336, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","19 loss:  tensor(0.8223, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","20 loss:  tensor(0.8126, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","21 loss:  tensor(0.8044, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","22 loss:  tensor(0.7973, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","23 loss:  tensor(0.7912, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","24 loss:  tensor(0.7861, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","25 loss:  tensor(0.7817, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","26 loss:  tensor(0.7779, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","27 loss:  tensor(0.7746, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","28 loss:  tensor(0.7718, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","29 loss:  tensor(0.7693, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","30 loss:  tensor(0.7672, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","31 loss:  tensor(0.7653, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","32 loss:  tensor(0.7636, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","33 loss:  tensor(0.7621, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","34 loss:  tensor(0.7608, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","35 loss:  tensor(0.7596, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","36 loss:  tensor(0.7585, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","37 loss:  tensor(0.7575, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","38 loss:  tensor(0.7566, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","39 loss:  tensor(0.7558, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","40 loss:  tensor(0.7550, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","41 loss:  tensor(0.7543, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","42 loss:  tensor(0.7537, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","43 loss:  tensor(0.7531, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","44 loss:  tensor(0.7525, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","45 loss:  tensor(0.7520, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","46 loss:  tensor(0.7515, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","47 loss:  tensor(0.7511, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","48 loss:  tensor(0.7506, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","49 loss:  tensor(0.7502, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","50 loss:  tensor(0.7499, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","51 loss:  tensor(0.7495, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","52 loss:  tensor(0.7492, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","53 loss:  tensor(0.7489, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","54 loss:  tensor(0.7486, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","55 loss:  tensor(0.7483, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","56 loss:  tensor(0.7480, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","57 loss:  tensor(0.7478, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","58 loss:  tensor(0.7475, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","59 loss:  tensor(0.7473, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","60 loss:  tensor(0.7471, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","61 loss:  tensor(0.7469, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","62 loss:  tensor(0.7467, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","63 loss:  tensor(0.7465, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","64 loss:  tensor(0.7463, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","65 loss:  tensor(0.7461, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","66 loss:  tensor(0.7460, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","67 loss:  tensor(0.7458, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","68 loss:  tensor(0.7456, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","69 loss:  tensor(0.7455, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","70 loss:  tensor(0.7453, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","71 loss:  tensor(0.7452, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","72 loss:  tensor(0.7450, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","73 loss:  tensor(0.7449, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","74 loss:  tensor(0.7448, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","75 loss:  tensor(0.7446, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","76 loss:  tensor(0.7445, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","77 loss:  tensor(0.7444, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","78 loss:  tensor(0.7443, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","79 loss:  tensor(0.7441, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","80 loss:  tensor(0.7440, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","81 loss:  tensor(0.7439, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","82 loss:  tensor(0.7438, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","83 loss:  tensor(0.7437, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","84 loss:  tensor(0.7436, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","85 loss:  tensor(0.7435, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","86 loss:  tensor(0.7434, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","87 loss:  tensor(0.7433, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","88 loss:  tensor(0.7432, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","89 loss:  tensor(0.7431, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","90 loss:  tensor(0.7430, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","91 loss:  tensor(0.7429, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","92 loss:  tensor(0.7428, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","93 loss:  tensor(0.7427, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","94 loss:  tensor(0.7426, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","95 loss:  tensor(0.7425, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","96 loss:  tensor(0.7424, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","97 loss:  tensor(0.7423, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","98 loss:  tensor(0.7422, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n","99 loss:  tensor(0.7422, grad_fn=<NllLossBackward0>)\n","prediction:  [[5 2 8 8 0 7 3 6 0 1 8 4]]  prediction_str:  hello! world\n"]}]},{"cell_type":"markdown","source":["### RNN의 단점\n","* 입력과 출력이 고정\n","* 기울기 소실\n","* 단점을 극복하기 위해 RNN의 발전 형태인 LSTM과 GRU를 사용(문제를 완벽히 해결하지 못함)"],"metadata":{"id":"t-Gb6OnaZtDT"}},{"cell_type":"code","source":[],"metadata":{"id":"nIIbt3HNZoW7"},"execution_count":null,"outputs":[]}]}